# ğŸš€ FastAPI Boilerplate â€“ Agents, ML & CI/CD Ready

Boilerplate de **FastAPI em Python** preparado para:
- ConstruÃ§Ã£o de **Agentes de IA**
- IntegraÃ§Ã£o com **LLMs**
- Pipelines simples de **Machine Learning**
- Observabilidade mÃ­nima
- ExecuÃ§Ã£o em ambientes de **CI/CD**

Este projeto **nÃ£o implementa regras de negÃ³cio**.  
Ele entrega **infraestrutura, organizaÃ§Ã£o e capacidade tÃ©cnica** para acelerar MVPs e produtos de IA.

---

## ğŸ¯ Objetivo

Fornecer uma base sÃ³lida, simples e extensÃ­vel para desenvolvimento de:
- APIs de agentes inteligentes
- ServiÃ§os de IA aplicada
- Backends para LLMs
- Provas de conceito rÃ¡pidas
- Produtos escalÃ¡veis desde o primeiro commit

Foco em:
- Clareza
- Extensibilidade
- ProntidÃ£o para produÃ§Ã£o
- Baixo atrito para o time

---

## ğŸ—‚ï¸ Estrutura do Projeto

```
app/
â”œâ”€ main.py                 # InicializaÃ§Ã£o da FastAPI
â”œâ”€ core/
â”‚   â”œâ”€ config.py           # ConfiguraÃ§Ãµes e env
â”‚   â”œâ”€ logging.py          # Logging estruturado
â”‚   â””â”€ middleware.py       # Middlewares globais
â”œâ”€ api/
â”‚   â””â”€ health.py           # Healthcheck
â”œâ”€ agents/
â”‚   â”œâ”€ base.py             # Classe base do agente
â”‚   â””â”€ context.py          # Contexto do agente
â”œâ”€ services/
â”‚   â””â”€ llm.py              # Cliente base de LLM
â”œâ”€ ml/
â”‚   â”œâ”€ pipeline.py         # Pipeline de ML
â”‚   â””â”€ models.py           # Modelos ML
tests/
â””â”€ test_health.py          # Testes bÃ¡sicos
```

---

## ğŸ“¦ DependÃªncias Principais

### API
- `fastapi` - Framework web moderno e rÃ¡pido
- `uvicorn` - Servidor ASGI
- `pydantic` - ValidaÃ§Ã£o de dados
- `python-dotenv` - Gerenciamento de variÃ¡veis de ambiente

### Agents & LLM
- `httpx` - Cliente HTTP assÃ­ncrono
- `tenacity` - Retry logic
- `loguru` - Logging avanÃ§ado

### ML (opcional)
- `numpy` - ComputaÃ§Ã£o numÃ©rica
- `pandas` - ManipulaÃ§Ã£o de dados
- `scikit-learn` - Machine Learning

---

## âš™ï¸ ConfiguraÃ§Ã£o

1. Copie o arquivo de exemplo:
```bash
cp .env.example .env
```

2. Configure as variÃ¡veis:
```env
APP_NAME=fastapi-agents
APP_ENV=local
DEBUG=true
LOG_LEVEL=INFO
LLM_PROVIDER=bedrock
```

---

## ğŸš€ Como Rodar

### Desenvolvimento
```bash
pip install -e ".[dev]"
uvicorn app.main:app --reload
```

### ProduÃ§Ã£o
```bash
pip install .
uvicorn app.main:app --host 0.0.0.0 --port 8000
```

### Testes
```bash
pytest
pytest --cov=app tests/
```

### Docker
```bash
docker build -t fastapi-agents .
docker run -p 8000:8000 fastapi-agents
```

---

## ğŸ“Š Endpoints

- `GET /health/` - Healthcheck da aplicaÃ§Ã£o
- `GET /docs` - DocumentaÃ§Ã£o Swagger
- `GET /redoc` - DocumentaÃ§Ã£o ReDoc

---

## ğŸ§  Agentes

A classe `BaseAgent` fornece estrutura bÃ¡sica para criaÃ§Ã£o de agentes:

```python
from app.agents.base import BaseAgent

class MeuAgente(BaseAgent):
    async def execute(self, input_data):
        # Sua lÃ³gica aqui
        return resultado
```

### Contexto de Agente

```python
from app.agents.context import AgentContext

context = AgentContext()
context.add("user_id", "123")
context.add("session", session_data)

# Recuperar dados
user_id = context.get("user_id")

# HistÃ³rico
history = context.get_history()
```

---

## ğŸ”Œ LLM Client

Cliente genÃ©rico para integraÃ§Ã£o com LLMs:

```python
from app.services.llm import LLMClient

llm = LLMClient("bedrock")
response = await llm.invoke("Seu prompt aqui")

# Streaming
async for chunk in llm.stream("Seu prompt"):
    print(chunk)
```

---

## ğŸ¤– Machine Learning

### Pipeline

```python
from app.ml.pipeline import MLPipeline

class MeuPipeline(MLPipeline):
    async def preprocess(self, data):
        # PrÃ©-processamento
        return processed_data
    
    async def predict(self, data):
        # InferÃªncia
        return predictions
    
    async def postprocess(self, predictions):
        # PÃ³s-processamento
        return result

# Uso
pipeline = MeuPipeline("meu-pipeline")
result = await pipeline.run(data)
```

### Modelos

```python
from app.ml.models import MLModel

model = MLModel("path/to/model.pkl")
model.load()
predictions = model.predict(data)
```

---

## ğŸ“ Logging

Logs estruturados com correlaÃ§Ã£o por `trace_id`:

```python
from app.core.logging import logger

logger.info("Mensagem", extra={"metadata": "valor"})
logger.error("Erro", extra={"error": str(e)})
```

Cada requisiÃ§Ã£o recebe um `trace_id` Ãºnico no header `X-Trace-ID`.

---

## ğŸ³ Docker

Imagem otimizada para produÃ§Ã£o:
- Python 3.11 slim
- Apenas dependÃªncias de produÃ§Ã£o
- Porta 8000 exposta

---

## ğŸ”’ PrincÃ­pios

- Boilerplate, nÃ£o framework
- Sem lock-in tecnolÃ³gico
- FÃ¡cil de estender
- Seguro por padrÃ£o
- Pronto para agentes, ML e LLMs
- EvoluÃ§Ã£o incremental

---

## âœ… PrÃ³ximos Passos

1. Implemente seu agente estendendo `BaseAgent`
2. Configure o provider LLM desejado (Bedrock, OpenAI, etc.)
3. Adicione suas rotas em `app/api/`
4. Crie pipelines ML em `app/ml/`
5. Expanda os testes conforme necessÃ¡rio

---

**Pronto para construir APIs inteligentes com Python! ğŸš€**
